{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In_class_exercise_09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Explorer9/INFO5731_FALL2020/blob/master/In_class_exercise_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhazgW_LZe4n"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 11/11/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GPrIIW9Ze4p"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92yS2o-cZe4q"
      },
      "source": [
        "# Write your code here\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "train=pd.read_csv(\"/content/stsa-train.csv\", encoding=\"cp1252\")\n",
        "train=train[{'1','a stirring,'}]\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "test=pd.read_csv(\"/content/stsa-test.csv\",header=None)\n",
        "test=test[{0,1}]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKx_HOR-5naB"
      },
      "source": [
        "x=np.array(train['a stirring,'])\n",
        "test_x=np.array(test[1])\n",
        "y=np.array(train['1'])\n",
        "test_y=np.array(test[0])\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "accuracy={}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwsfPM05-J3Z"
      },
      "source": [
        "#multinb\n",
        "text_clf_multinb = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB())])\n",
        "text_clf_multinb.fit(X_train, y_train)\n",
        "accuracy['multinb']=metrics.accuracy_score(y_test,predicted)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B98E4q4V_X9Q",
        "outputId": "5923a3a2-9b0e-4beb-abe5-3bf0cc7388db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predicted = text_clf_multinb.predict(X_test)                       #validaition on validation dataset\n",
        "scores = cross_val_score(text_clf_multinb, test_x, test_y, cv=10)  #10 fold cross validation\n",
        "print(metrics.classification_report(y_test, predicted))\n",
        "print(\"cros_val_accuracy:\",scores.mean())\n",
        "accuracy['multinb']=metrics.accuracy_score(y_test,predicted)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.67      0.71       653\n",
            "           1       0.73      0.81      0.77       731\n",
            "\n",
            "    accuracy                           0.74      1384\n",
            "   macro avg       0.74      0.74      0.74      1384\n",
            "weighted avg       0.74      0.74      0.74      1384\n",
            "\n",
            "cros_val_accuracy: 0.7385996517144059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpzQsX-vFiXF",
        "outputId": "c27216bb-7dee-480d-a0f0-a678200d453d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#svm\n",
        "text_clf_svm = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', LinearSVC())])\n",
        "text_clf_svm.fit(X_train, y_train)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY8G2QZEFpE2",
        "outputId": "a99983a3-b0b2-4f82-9d01-f319bdd48ec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predicted = text_clf_svm.predict(X_test)\n",
        "scores = cross_val_score(text_clf_svm, test_x, test_y, cv=10)\n",
        "print(\"cros_val_accuracy:\",scores.mean())\n",
        "print(metrics.classification_report(y_test, predicted))\n",
        "accuracy['svm']=metrics.accuracy_score(y_test,predicted)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cros_val_accuracy: 0.7226896054764907\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.69      0.70       653\n",
            "           1       0.73      0.75      0.74       731\n",
            "\n",
            "    accuracy                           0.72      1384\n",
            "   macro avg       0.72      0.72      0.72      1384\n",
            "weighted avg       0.72      0.72      0.72      1384\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkMkIfv5GGiL"
      },
      "source": [
        "#knn\n",
        "text_clf_knn = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', KNeighborsClassifier())])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoQoMzoRGrqV",
        "outputId": "69b1773c-b16d-4f09-f233-099dfc25faeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text_clf_knn.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predicted = text_clf_knn.predict(X_test)\n",
        "\n",
        "print(metrics.classification_report(y_test, predicted))\n",
        "scores = cross_val_score(text_clf_knn, test_x, test_y, cv=10)\n",
        "print(\"cros_val_accuracy:\",scores.mean())\n",
        "accuracy['knn']=metrics.accuracy_score(y_test,predicted)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.02      0.04       653\n",
            "           1       0.53      1.00      0.69       731\n",
            "\n",
            "    accuracy                           0.54      1384\n",
            "   macro avg       0.68      0.51      0.37      1384\n",
            "weighted avg       0.67      0.54      0.39      1384\n",
            "\n",
            "cros_val_accuracy: 0.6688734762505255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96pjQJz0GyGi"
      },
      "source": [
        "#decision tree\n",
        "text_clf_tree = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', tree.DecisionTreeClassifier())])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYtPVgg1Hjo4",
        "outputId": "7c4696eb-9f4c-4256-b521-e6c6c29495b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text_clf_tree.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predicted = text_clf_tree.predict(X_test)\n",
        "\n",
        "print(metrics.classification_report(y_test, predicted))\n",
        "scores = cross_val_score(text_clf_tree, test_x, test_y, cv=10)\n",
        "print(\"cros_val_accuracy:\",scores.mean())\n",
        "accuracy['decisin_tree']=metrics.accuracy_score(y_test,predicted)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.52      0.55       653\n",
            "           1       0.61      0.66      0.63       731\n",
            "\n",
            "    accuracy                           0.59      1384\n",
            "   macro avg       0.59      0.59      0.59      1384\n",
            "weighted avg       0.59      0.59      0.59      1384\n",
            "\n",
            "cros_val_accuracy: 0.600768630276827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78C07dQoHzt1"
      },
      "source": [
        "#random forest\n",
        "text_clf_forest = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', RandomForestClassifier(n_estimators=100))])\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvpb3tTYIQT1",
        "outputId": "66cbaac9-e6d3-41b1-fbc0-7c2d8f15e36d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text_clf_forest.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predicted = text_clf_forest.predict(X_test)\n",
        "\n",
        "print(metrics.classification_report(y_test, predicted))\n",
        "scores = cross_val_score(text_clf_forest, test_x, test_y, cv=10)\n",
        "print(\"cros_val_accuracy:\",scores.mean())\n",
        "accuracy['forest']=metrics.accuracy_score(y_test,predicted)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.55      0.61       653\n",
            "           1       0.66      0.78      0.71       731\n",
            "\n",
            "    accuracy                           0.67      1384\n",
            "   macro avg       0.67      0.66      0.66      1384\n",
            "weighted avg       0.67      0.67      0.67      1384\n",
            "\n",
            "cros_val_accuracy: 0.6644748693929022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuaR0Y83ITVo"
      },
      "source": [
        "#xgboost\n",
        "text_clf_boost = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', GradientBoostingClassifier(n_estimators=50,verbose=2))])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6YWzHsjI2VK",
        "outputId": "fb9f3b60-4b29-4cf5-e0fc-0370fb0f4b69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text_clf_boost.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predicted = text_clf_boost.predict(X_test)\n",
        "\n",
        "print(metrics.classification_report(y_test, predicted))\n",
        "scores = cross_val_score(text_clf_boost,test_x, test_y, cv=10)\n",
        "print(\"cros_val_accuracy:\",scores.mean())\n",
        "accuracy['xgboost']=metrics.accuracy_score(y_test,predicted)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3783            1.24s\n",
            "         2           1.3729            1.19s\n",
            "         3           1.3680            1.16s\n",
            "         4           1.3640            1.15s\n",
            "         5           1.3605            1.12s\n",
            "         6           1.3568            1.09s\n",
            "         7           1.3530            1.08s\n",
            "         8           1.3499            1.05s\n",
            "         9           1.3470            1.04s\n",
            "        10           1.3440            1.02s\n",
            "        11           1.3413            0.99s\n",
            "        12           1.3386            0.96s\n",
            "        13           1.3357            0.93s\n",
            "        14           1.3333            0.91s\n",
            "        15           1.3312            0.88s\n",
            "        16           1.3287            0.84s\n",
            "        17           1.3261            0.80s\n",
            "        18           1.3236            0.77s\n",
            "        19           1.3211            0.73s\n",
            "        20           1.3190            0.70s\n",
            "        21           1.3162            0.67s\n",
            "        22           1.3139            0.65s\n",
            "        23           1.3118            0.63s\n",
            "        24           1.3098            0.61s\n",
            "        25           1.3082            0.58s\n",
            "        26           1.3062            0.56s\n",
            "        27           1.3042            0.54s\n",
            "        28           1.3021            0.52s\n",
            "        29           1.3000            0.50s\n",
            "        30           1.2983            0.48s\n",
            "        31           1.2967            0.45s\n",
            "        32           1.2948            0.43s\n",
            "        33           1.2929            0.41s\n",
            "        34           1.2909            0.38s\n",
            "        35           1.2892            0.36s\n",
            "        36           1.2876            0.34s\n",
            "        37           1.2862            0.31s\n",
            "        38           1.2844            0.29s\n",
            "        39           1.2828            0.27s\n",
            "        40           1.2807            0.24s\n",
            "        41           1.2789            0.22s\n",
            "        42           1.2774            0.19s\n",
            "        43           1.2756            0.17s\n",
            "        44           1.2739            0.15s\n",
            "        45           1.2723            0.12s\n",
            "        46           1.2709            0.10s\n",
            "        47           1.2696            0.07s\n",
            "        48           1.2679            0.05s\n",
            "        49           1.2665            0.02s\n",
            "        50           1.2651            0.00s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.34      0.45       653\n",
            "           1       0.59      0.85      0.70       731\n",
            "\n",
            "    accuracy                           0.61      1384\n",
            "   macro avg       0.63      0.60      0.58      1384\n",
            "weighted avg       0.63      0.61      0.58      1384\n",
            "\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3722            0.57s\n",
            "         2           1.3605            0.58s\n",
            "         3           1.3506            0.56s\n",
            "         4           1.3414            0.55s\n",
            "         5           1.3331            0.53s\n",
            "         6           1.3245            0.51s\n",
            "         7           1.3172            0.50s\n",
            "         8           1.3118            0.48s\n",
            "         9           1.3053            0.46s\n",
            "        10           1.2986            0.46s\n",
            "        11           1.2927            0.44s\n",
            "        12           1.2883            0.43s\n",
            "        13           1.2836            0.42s\n",
            "        14           1.2783            0.41s\n",
            "        15           1.2726            0.39s\n",
            "        16           1.2688            0.37s\n",
            "        17           1.2642            0.35s\n",
            "        18           1.2594            0.33s\n",
            "        19           1.2539            0.32s\n",
            "        20           1.2507            0.31s\n",
            "        21           1.2476            0.29s\n",
            "        22           1.2439            0.28s\n",
            "        23           1.2402            0.27s\n",
            "        24           1.2362            0.25s\n",
            "        25           1.2333            0.24s\n",
            "        26           1.2271            0.23s\n",
            "        27           1.2234            0.22s\n",
            "        28           1.2204            0.21s\n",
            "        29           1.2160            0.20s\n",
            "        30           1.2122            0.19s\n",
            "        31           1.2089            0.18s\n",
            "        32           1.2057            0.17s\n",
            "        33           1.2019            0.16s\n",
            "        34           1.1984            0.15s\n",
            "        35           1.1950            0.14s\n",
            "        36           1.1924            0.13s\n",
            "        37           1.1892            0.13s\n",
            "        38           1.1855            0.12s\n",
            "        39           1.1826            0.11s\n",
            "        40           1.1786            0.10s\n",
            "        41           1.1757            0.09s\n",
            "        42           1.1733            0.08s\n",
            "        43           1.1693            0.07s\n",
            "        44           1.1667            0.06s\n",
            "        45           1.1642            0.05s\n",
            "        46           1.1615            0.04s\n",
            "        47           1.1573            0.03s\n",
            "        48           1.1551            0.02s\n",
            "        49           1.1518            0.01s\n",
            "        50           1.1487            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3728            0.59s\n",
            "         2           1.3614            0.57s\n",
            "         3           1.3511            0.56s\n",
            "         4           1.3421            0.54s\n",
            "         5           1.3337            0.52s\n",
            "         6           1.3267            0.53s\n",
            "         7           1.3191            0.51s\n",
            "         8           1.3129            0.49s\n",
            "         9           1.3059            0.48s\n",
            "        10           1.2998            0.46s\n",
            "        11           1.2936            0.45s\n",
            "        12           1.2881            0.44s\n",
            "        13           1.2831            0.42s\n",
            "        14           1.2784            0.41s\n",
            "        15           1.2743            0.40s\n",
            "        16           1.2692            0.38s\n",
            "        17           1.2658            0.37s\n",
            "        18           1.2604            0.36s\n",
            "        19           1.2550            0.34s\n",
            "        20           1.2507            0.33s\n",
            "        21           1.2469            0.32s\n",
            "        22           1.2426            0.31s\n",
            "        23           1.2396            0.30s\n",
            "        24           1.2360            0.28s\n",
            "        25           1.2312            0.27s\n",
            "        26           1.2263            0.26s\n",
            "        27           1.2219            0.25s\n",
            "        28           1.2181            0.24s\n",
            "        29           1.2151            0.23s\n",
            "        30           1.2121            0.22s\n",
            "        31           1.2087            0.21s\n",
            "        32           1.2052            0.20s\n",
            "        33           1.2026            0.19s\n",
            "        34           1.2000            0.18s\n",
            "        35           1.1964            0.16s\n",
            "        36           1.1930            0.15s\n",
            "        37           1.1895            0.14s\n",
            "        38           1.1871            0.13s\n",
            "        39           1.1844            0.12s\n",
            "        40           1.1810            0.11s\n",
            "        41           1.1787            0.10s\n",
            "        42           1.1760            0.09s\n",
            "        43           1.1734            0.08s\n",
            "        44           1.1704            0.06s\n",
            "        45           1.1682            0.05s\n",
            "        46           1.1651            0.04s\n",
            "        47           1.1625            0.03s\n",
            "        48           1.1591            0.02s\n",
            "        49           1.1567            0.01s\n",
            "        50           1.1515            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3726            0.54s\n",
            "         2           1.3614            0.53s\n",
            "         3           1.3513            0.52s\n",
            "         4           1.3423            0.52s\n",
            "         5           1.3344            0.50s\n",
            "         6           1.3262            0.50s\n",
            "         7           1.3199            0.49s\n",
            "         8           1.3134            0.48s\n",
            "         9           1.3076            0.46s\n",
            "        10           1.3016            0.46s\n",
            "        11           1.2968            0.44s\n",
            "        12           1.2901            0.43s\n",
            "        13           1.2831            0.42s\n",
            "        14           1.2791            0.41s\n",
            "        15           1.2741            0.40s\n",
            "        16           1.2698            0.39s\n",
            "        17           1.2654            0.37s\n",
            "        18           1.2604            0.36s\n",
            "        19           1.2551            0.35s\n",
            "        20           1.2517            0.34s\n",
            "        21           1.2480            0.33s\n",
            "        22           1.2444            0.31s\n",
            "        23           1.2404            0.30s\n",
            "        24           1.2374            0.29s\n",
            "        25           1.2329            0.28s\n",
            "        26           1.2301            0.27s\n",
            "        27           1.2258            0.26s\n",
            "        28           1.2228            0.24s\n",
            "        29           1.2178            0.24s\n",
            "        30           1.2128            0.22s\n",
            "        31           1.2089            0.21s\n",
            "        32           1.2059            0.20s\n",
            "        33           1.2016            0.19s\n",
            "        34           1.1979            0.18s\n",
            "        35           1.1935            0.17s\n",
            "        36           1.1906            0.16s\n",
            "        37           1.1875            0.14s\n",
            "        38           1.1839            0.13s\n",
            "        39           1.1815            0.12s\n",
            "        40           1.1792            0.11s\n",
            "        41           1.1765            0.10s\n",
            "        42           1.1731            0.09s\n",
            "        43           1.1706            0.08s\n",
            "        44           1.1681            0.07s\n",
            "        45           1.1650            0.06s\n",
            "        46           1.1628            0.04s\n",
            "        47           1.1593            0.03s\n",
            "        48           1.1561            0.02s\n",
            "        49           1.1538            0.01s\n",
            "        50           1.1509            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3724            0.57s\n",
            "         2           1.3605            0.56s\n",
            "         3           1.3501            0.54s\n",
            "         4           1.3400            0.53s\n",
            "         5           1.3315            0.52s\n",
            "         6           1.3237            0.51s\n",
            "         7           1.3166            0.49s\n",
            "         8           1.3099            0.48s\n",
            "         9           1.3036            0.47s\n",
            "        10           1.2975            0.47s\n",
            "        11           1.2933            0.46s\n",
            "        12           1.2876            0.45s\n",
            "        13           1.2832            0.44s\n",
            "        14           1.2785            0.42s\n",
            "        15           1.2717            0.41s\n",
            "        16           1.2666            0.40s\n",
            "        17           1.2621            0.39s\n",
            "        18           1.2582            0.37s\n",
            "        19           1.2545            0.36s\n",
            "        20           1.2513            0.35s\n",
            "        21           1.2476            0.34s\n",
            "        22           1.2424            0.33s\n",
            "        23           1.2385            0.32s\n",
            "        24           1.2357            0.30s\n",
            "        25           1.2303            0.29s\n",
            "        26           1.2268            0.28s\n",
            "        27           1.2240            0.27s\n",
            "        28           1.2195            0.25s\n",
            "        29           1.2159            0.24s\n",
            "        30           1.2126            0.23s\n",
            "        31           1.2090            0.22s\n",
            "        32           1.2065            0.21s\n",
            "        33           1.2032            0.20s\n",
            "        34           1.1984            0.19s\n",
            "        35           1.1957            0.17s\n",
            "        36           1.1929            0.16s\n",
            "        37           1.1899            0.15s\n",
            "        38           1.1866            0.14s\n",
            "        39           1.1839            0.13s\n",
            "        40           1.1798            0.11s\n",
            "        41           1.1771            0.10s\n",
            "        42           1.1746            0.09s\n",
            "        43           1.1716            0.08s\n",
            "        44           1.1675            0.07s\n",
            "        45           1.1651            0.06s\n",
            "        46           1.1628            0.05s\n",
            "        47           1.1599            0.03s\n",
            "        48           1.1577            0.02s\n",
            "        49           1.1544            0.01s\n",
            "        50           1.1518            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3730            0.58s\n",
            "         2           1.3619            0.56s\n",
            "         3           1.3515            0.54s\n",
            "         4           1.3406            0.52s\n",
            "         5           1.3325            0.51s\n",
            "         6           1.3241            0.49s\n",
            "         7           1.3168            0.48s\n",
            "         8           1.3101            0.46s\n",
            "         9           1.3052            0.45s\n",
            "        10           1.2991            0.44s\n",
            "        11           1.2926            0.42s\n",
            "        12           1.2887            0.41s\n",
            "        13           1.2832            0.40s\n",
            "        14           1.2788            0.39s\n",
            "        15           1.2742            0.39s\n",
            "        16           1.2681            0.37s\n",
            "        17           1.2643            0.36s\n",
            "        18           1.2605            0.35s\n",
            "        19           1.2558            0.34s\n",
            "        20           1.2507            0.33s\n",
            "        21           1.2473            0.31s\n",
            "        22           1.2427            0.30s\n",
            "        23           1.2394            0.29s\n",
            "        24           1.2355            0.28s\n",
            "        25           1.2322            0.27s\n",
            "        26           1.2294            0.26s\n",
            "        27           1.2260            0.25s\n",
            "        28           1.2217            0.24s\n",
            "        29           1.2184            0.23s\n",
            "        30           1.2137            0.22s\n",
            "        31           1.2101            0.21s\n",
            "        32           1.2054            0.20s\n",
            "        33           1.2010            0.19s\n",
            "        34           1.1963            0.18s\n",
            "        35           1.1922            0.16s\n",
            "        36           1.1886            0.15s\n",
            "        37           1.1855            0.14s\n",
            "        38           1.1831            0.13s\n",
            "        39           1.1796            0.12s\n",
            "        40           1.1766            0.11s\n",
            "        41           1.1739            0.10s\n",
            "        42           1.1713            0.09s\n",
            "        43           1.1688            0.08s\n",
            "        44           1.1664            0.07s\n",
            "        45           1.1636            0.05s\n",
            "        46           1.1606            0.04s\n",
            "        47           1.1583            0.03s\n",
            "        48           1.1559            0.02s\n",
            "        49           1.1528            0.01s\n",
            "        50           1.1500            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3725            0.58s\n",
            "         2           1.3604            0.56s\n",
            "         3           1.3500            0.59s\n",
            "         4           1.3414            0.58s\n",
            "         5           1.3332            0.56s\n",
            "         6           1.3242            0.54s\n",
            "         7           1.3172            0.52s\n",
            "         8           1.3091            0.50s\n",
            "         9           1.3038            0.48s\n",
            "        10           1.2989            0.47s\n",
            "        11           1.2922            0.45s\n",
            "        12           1.2875            0.44s\n",
            "        13           1.2831            0.42s\n",
            "        14           1.2776            0.41s\n",
            "        15           1.2728            0.40s\n",
            "        16           1.2687            0.39s\n",
            "        17           1.2632            0.37s\n",
            "        18           1.2595            0.36s\n",
            "        19           1.2555            0.35s\n",
            "        20           1.2524            0.34s\n",
            "        21           1.2488            0.33s\n",
            "        22           1.2445            0.32s\n",
            "        23           1.2414            0.30s\n",
            "        24           1.2375            0.29s\n",
            "        25           1.2339            0.28s\n",
            "        26           1.2300            0.27s\n",
            "        27           1.2254            0.26s\n",
            "        28           1.2221            0.24s\n",
            "        29           1.2179            0.23s\n",
            "        30           1.2152            0.22s\n",
            "        31           1.2115            0.21s\n",
            "        32           1.2084            0.20s\n",
            "        33           1.2054            0.19s\n",
            "        34           1.2026            0.17s\n",
            "        35           1.1988            0.16s\n",
            "        36           1.1958            0.15s\n",
            "        37           1.1933            0.14s\n",
            "        38           1.1900            0.13s\n",
            "        39           1.1862            0.12s\n",
            "        40           1.1834            0.11s\n",
            "        41           1.1810            0.10s\n",
            "        42           1.1778            0.09s\n",
            "        43           1.1746            0.08s\n",
            "        44           1.1721            0.07s\n",
            "        45           1.1693            0.05s\n",
            "        46           1.1664            0.04s\n",
            "        47           1.1641            0.03s\n",
            "        48           1.1612            0.02s\n",
            "        49           1.1585            0.01s\n",
            "        50           1.1565            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3729            0.56s\n",
            "         2           1.3610            0.55s\n",
            "         3           1.3505            0.56s\n",
            "         4           1.3411            0.55s\n",
            "         5           1.3331            0.55s\n",
            "         6           1.3249            0.53s\n",
            "         7           1.3189            0.51s\n",
            "         8           1.3114            0.49s\n",
            "         9           1.3048            0.48s\n",
            "        10           1.2993            0.46s\n",
            "        11           1.2940            0.45s\n",
            "        12           1.2872            0.43s\n",
            "        13           1.2816            0.42s\n",
            "        14           1.2754            0.41s\n",
            "        15           1.2700            0.40s\n",
            "        16           1.2655            0.38s\n",
            "        17           1.2615            0.37s\n",
            "        18           1.2577            0.36s\n",
            "        19           1.2521            0.35s\n",
            "        20           1.2480            0.34s\n",
            "        21           1.2429            0.32s\n",
            "        22           1.2382            0.31s\n",
            "        23           1.2346            0.30s\n",
            "        24           1.2313            0.29s\n",
            "        25           1.2273            0.27s\n",
            "        26           1.2241            0.26s\n",
            "        27           1.2195            0.25s\n",
            "        28           1.2158            0.24s\n",
            "        29           1.2126            0.23s\n",
            "        30           1.2083            0.22s\n",
            "        31           1.2049            0.21s\n",
            "        32           1.2012            0.20s\n",
            "        33           1.1985            0.19s\n",
            "        34           1.1954            0.17s\n",
            "        35           1.1921            0.16s\n",
            "        36           1.1877            0.15s\n",
            "        37           1.1847            0.14s\n",
            "        38           1.1820            0.13s\n",
            "        39           1.1785            0.12s\n",
            "        40           1.1761            0.11s\n",
            "        41           1.1732            0.10s\n",
            "        42           1.1690            0.09s\n",
            "        43           1.1658            0.08s\n",
            "        44           1.1629            0.07s\n",
            "        45           1.1597            0.05s\n",
            "        46           1.1564            0.04s\n",
            "        47           1.1541            0.03s\n",
            "        48           1.1517            0.02s\n",
            "        49           1.1490            0.01s\n",
            "        50           1.1467            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3733            0.60s\n",
            "         2           1.3622            0.57s\n",
            "         3           1.3512            0.55s\n",
            "         4           1.3423            0.53s\n",
            "         5           1.3341            0.52s\n",
            "         6           1.3264            0.51s\n",
            "         7           1.3188            0.53s\n",
            "         8           1.3123            0.52s\n",
            "         9           1.3071            0.49s\n",
            "        10           1.3024            0.48s\n",
            "        11           1.2954            0.46s\n",
            "        12           1.2907            0.45s\n",
            "        13           1.2860            0.43s\n",
            "        14           1.2794            0.42s\n",
            "        15           1.2739            0.41s\n",
            "        16           1.2687            0.39s\n",
            "        17           1.2646            0.37s\n",
            "        18           1.2605            0.36s\n",
            "        19           1.2562            0.34s\n",
            "        20           1.2517            0.32s\n",
            "        21           1.2480            0.31s\n",
            "        22           1.2442            0.30s\n",
            "        23           1.2408            0.29s\n",
            "        24           1.2363            0.28s\n",
            "        25           1.2314            0.27s\n",
            "        26           1.2278            0.26s\n",
            "        27           1.2238            0.25s\n",
            "        28           1.2195            0.24s\n",
            "        29           1.2162            0.23s\n",
            "        30           1.2126            0.22s\n",
            "        31           1.2083            0.21s\n",
            "        32           1.2051            0.20s\n",
            "        33           1.2021            0.19s\n",
            "        34           1.1994            0.18s\n",
            "        35           1.1969            0.17s\n",
            "        36           1.1935            0.15s\n",
            "        37           1.1905            0.14s\n",
            "        38           1.1869            0.13s\n",
            "        39           1.1837            0.12s\n",
            "        40           1.1797            0.11s\n",
            "        41           1.1770            0.10s\n",
            "        42           1.1730            0.09s\n",
            "        43           1.1700            0.08s\n",
            "        44           1.1672            0.07s\n",
            "        45           1.1645            0.05s\n",
            "        46           1.1612            0.04s\n",
            "        47           1.1590            0.03s\n",
            "        48           1.1568            0.02s\n",
            "        49           1.1540            0.01s\n",
            "        50           1.1517            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3736            0.57s\n",
            "         2           1.3626            0.55s\n",
            "         3           1.3532            0.54s\n",
            "         4           1.3444            0.52s\n",
            "         5           1.3367            0.51s\n",
            "         6           1.3297            0.49s\n",
            "         7           1.3246            0.47s\n",
            "         8           1.3179            0.46s\n",
            "         9           1.3122            0.45s\n",
            "        10           1.3046            0.44s\n",
            "        11           1.2984            0.43s\n",
            "        12           1.2940            0.43s\n",
            "        13           1.2884            0.41s\n",
            "        14           1.2827            0.40s\n",
            "        15           1.2785            0.39s\n",
            "        16           1.2727            0.38s\n",
            "        17           1.2675            0.37s\n",
            "        18           1.2643            0.36s\n",
            "        19           1.2608            0.34s\n",
            "        20           1.2577            0.33s\n",
            "        21           1.2530            0.32s\n",
            "        22           1.2491            0.31s\n",
            "        23           1.2439            0.29s\n",
            "        24           1.2393            0.28s\n",
            "        25           1.2359            0.27s\n",
            "        26           1.2332            0.26s\n",
            "        27           1.2296            0.25s\n",
            "        28           1.2251            0.24s\n",
            "        29           1.2217            0.23s\n",
            "        30           1.2183            0.22s\n",
            "        31           1.2151            0.21s\n",
            "        32           1.2117            0.20s\n",
            "        33           1.2069            0.19s\n",
            "        34           1.2033            0.17s\n",
            "        35           1.2009            0.16s\n",
            "        36           1.1983            0.15s\n",
            "        37           1.1952            0.14s\n",
            "        38           1.1920            0.13s\n",
            "        39           1.1892            0.12s\n",
            "        40           1.1866            0.11s\n",
            "        41           1.1833            0.10s\n",
            "        42           1.1800            0.09s\n",
            "        43           1.1762            0.08s\n",
            "        44           1.1737            0.06s\n",
            "        45           1.1712            0.05s\n",
            "        46           1.1690            0.04s\n",
            "        47           1.1660            0.03s\n",
            "        48           1.1635            0.02s\n",
            "        49           1.1606            0.01s\n",
            "        50           1.1586            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3736            0.58s\n",
            "         2           1.3632            0.53s\n",
            "         3           1.3530            0.52s\n",
            "         4           1.3439            0.51s\n",
            "         5           1.3364            0.49s\n",
            "         6           1.3275            0.48s\n",
            "         7           1.3205            0.47s\n",
            "         8           1.3147            0.46s\n",
            "         9           1.3071            0.45s\n",
            "        10           1.3018            0.44s\n",
            "        11           1.2960            0.43s\n",
            "        12           1.2896            0.42s\n",
            "        13           1.2850            0.40s\n",
            "        14           1.2785            0.39s\n",
            "        15           1.2729            0.38s\n",
            "        16           1.2693            0.37s\n",
            "        17           1.2641            0.36s\n",
            "        18           1.2598            0.34s\n",
            "        19           1.2561            0.34s\n",
            "        20           1.2503            0.33s\n",
            "        21           1.2470            0.32s\n",
            "        22           1.2431            0.30s\n",
            "        23           1.2396            0.29s\n",
            "        24           1.2362            0.28s\n",
            "        25           1.2327            0.27s\n",
            "        26           1.2297            0.26s\n",
            "        27           1.2269            0.25s\n",
            "        28           1.2218            0.24s\n",
            "        29           1.2177            0.23s\n",
            "        30           1.2138            0.22s\n",
            "        31           1.2097            0.21s\n",
            "        32           1.2062            0.20s\n",
            "        33           1.2033            0.19s\n",
            "        34           1.2000            0.18s\n",
            "        35           1.1951            0.17s\n",
            "        36           1.1919            0.16s\n",
            "        37           1.1894            0.14s\n",
            "        38           1.1861            0.13s\n",
            "        39           1.1837            0.12s\n",
            "        40           1.1806            0.11s\n",
            "        41           1.1763            0.10s\n",
            "        42           1.1721            0.09s\n",
            "        43           1.1697            0.08s\n",
            "        44           1.1670            0.07s\n",
            "        45           1.1639            0.06s\n",
            "        46           1.1610            0.04s\n",
            "        47           1.1577            0.03s\n",
            "        48           1.1555            0.02s\n",
            "        49           1.1526            0.01s\n",
            "        50           1.1496            0.00s\n",
            "cros_val_accuracy: 0.6161472407374047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1YYlcHRI43h",
        "outputId": "e8d51a8b-2f1b-4f09-f0f7-e1409dcd821f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'decisin_tree': 0.5932080924855492,\n",
              " 'forest': 0.671242774566474,\n",
              " 'knn': 0.5361271676300579,\n",
              " 'multinb': 0.740606936416185,\n",
              " 'svm': 0.7210982658959537,\n",
              " 'xgboost': 0.6119942196531792}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9JhOYwndmxq"
      },
      "source": [
        "we can infer from above cell, that accuracy of multinomial naive bayes is highest that is 74% comapred to other algorithms "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}