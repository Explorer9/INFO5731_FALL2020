{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Explorer9/INFO5731_FALL2020/blob/master/Copy_of_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis, and regression analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you understand topic modeling better as well as how to visualize topic modeling results, aims to collect the human meanings of documents. Based on the yelp review data (only the review text will be used for this question), which can be download from Dropbox: https://www.dropbox.com/s/59hsrk56sfwh9u2/Assignment%20four%20data%20Yelp%20%28question%201%20and%202%29.zip?dl=0, **select two models** and write a python program to **identify the top 20 topics (with 15 words for each topic) in the dataset**. Before answering this question, please review the materials in lesson 8, as well as the introduction of these models by the links provided.\n",
        "\n",
        "(1)   Labeled LDA (LLDA): https://github.com/JoeZJH/Labeled-LDA-Python\n",
        "\n",
        "(2)   Biterm Topic Model (BTM): https://github.com/markoarnauto/biterm\n",
        "\n",
        "(3)   HMM-LDA: https://github.com/dongwookim-ml/python-topic-model\n",
        "\n",
        "(4)   SupervisedLDA: https://github.com/dongwookim-ml/python-topic-model/tree/master/notebook\n",
        "\n",
        "(5)   Relational Topic Model: https://github.com/dongwookim-ml/python-topic-model/tree/master/notebook\n",
        "\n",
        "(6)   LDA2VEC: https://github.com/cemoody/lda2vec\n",
        "\n",
        "(7)   BERTopic: https://github.com/MaartenGr/BERTopic\n",
        "\n",
        "(8)   LDA+BERT Topic Modeling: https://www.kaggle.com/dskswu/topic-modeling-bert-lda\n",
        "\n",
        "(9)   Clustering for Topic models: (paper: https://arxiv.org/abs/2004.14914), (code: https://github.com/adalmia96/Cluster-Analysis)\n",
        "\n",
        "\n",
        "**The following information should be reported:**\n",
        "\n",
        "(1) Top 20 clusters for topic modeling.\n",
        "\n",
        "(2) Summarize and describe the topic for each cluster. \n",
        "\n",
        "(3) Visualize the topic modeling reasults by using pyLDAVis: https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/#14.-pyLDAVis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFPKhC0m1fd"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "file_name=[]\n",
        "df=pd.DataFrame()\n",
        "reviews=[]\n",
        "ratings=[]\n",
        "path='/content/test'\n",
        "import os\n",
        "for root, dirs, files in os.walk(path, topdown=False):\n",
        "  for i in files:\n",
        "    f=open('/content/test/'+i,)\n",
        "    data=json.load(f)\n",
        "    for j in data:\n",
        "      ratings.append(j['stars'])\n",
        "      reviews.append(j['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtpwoDGyweEc"
      },
      "source": [
        "df=pd.DataFrame()\n",
        "df['reviews']=reviews\n",
        "df['ratings']=ratings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfDApm2UmdQE"
      },
      "source": [
        "!git clone \"https://github.com/dongwookim-ml/python-topic-model.git\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbX4WnJKmlF_"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/python-topic-model')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_lG9vaTmpsX"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ptm import GibbsSupervisedLDA\n",
        "from ptm.nltk_corpus import get_ids_cnt\n",
        "from ptm.utils import convert_cnt_to_list, get_top_words\n",
        "\n",
        "%matplotlib inline  \n",
        "\n",
        "logger = logging.getLogger('GibbsSupervisedLDA')\n",
        "logger.propagate = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0pekIqFnCXM",
        "outputId": "e0aa63e7-7b62-46c7-f9bf-4f31f39f5ba4"
      },
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "voca, word_ids, word_cnt = get_ids_cnt(reviews)\n",
        "corpus = convert_cnt_to_list(word_ids, word_cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ySaxuGMLpH2-",
        "outputId": "ef6d2ee6-ddce-4405-c50f-b34304040554"
      },
      "source": [
        "n_doc = len(corpus)\n",
        "n_voca = voca.size\n",
        "print('num doc', n_doc, 'num_voca', n_voca)\n",
        "plt.hist(ratings, bins=5)\n",
        "plt.show()\n",
        "print('max rating', np.max(ratings), '\\tmin rating', np.min(ratings))\n",
        "n_topic = 20\n",
        "r_var = 0.01\n",
        "\n",
        "model = GibbsSupervisedLDA(n_doc, n_voca, n_topic, sigma=r_var)\n",
        "model.fit(corpus, ratings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num doc 2100 num_voca 7178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "max rating 5.0 \tmin rating 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-02 08:50:26 INFO:GibbsSupervisedLDA:[ITER] 0,\tMAE:0.46,\tlog_likelihood:-845638.02\n",
            "2020-12-02 08:50:31 INFO:GibbsSupervisedLDA:[ITER] 1,\tMAE:0.09,\tlog_likelihood:-791233.89\n",
            "2020-12-02 08:50:36 INFO:GibbsSupervisedLDA:[ITER] 2,\tMAE:0.09,\tlog_likelihood:-778858.83\n",
            "2020-12-02 08:50:40 INFO:GibbsSupervisedLDA:[ITER] 3,\tMAE:0.09,\tlog_likelihood:-771919.02\n",
            "2020-12-02 08:50:45 INFO:GibbsSupervisedLDA:[ITER] 4,\tMAE:0.09,\tlog_likelihood:-767536.48\n",
            "2020-12-02 08:50:50 INFO:GibbsSupervisedLDA:[ITER] 5,\tMAE:0.09,\tlog_likelihood:-763727.27\n",
            "2020-12-02 08:50:55 INFO:GibbsSupervisedLDA:[ITER] 6,\tMAE:0.09,\tlog_likelihood:-761118.75\n",
            "2020-12-02 08:50:59 INFO:GibbsSupervisedLDA:[ITER] 7,\tMAE:0.09,\tlog_likelihood:-758957.02\n",
            "2020-12-02 08:51:04 INFO:GibbsSupervisedLDA:[ITER] 8,\tMAE:0.09,\tlog_likelihood:-757446.99\n",
            "2020-12-02 08:51:09 INFO:GibbsSupervisedLDA:[ITER] 9,\tMAE:0.09,\tlog_likelihood:-755512.60\n",
            "2020-12-02 08:51:13 INFO:GibbsSupervisedLDA:[ITER] 10,\tMAE:0.08,\tlog_likelihood:-754411.00\n",
            "2020-12-02 08:51:18 INFO:GibbsSupervisedLDA:[ITER] 11,\tMAE:0.09,\tlog_likelihood:-752686.98\n",
            "2020-12-02 08:51:23 INFO:GibbsSupervisedLDA:[ITER] 12,\tMAE:0.09,\tlog_likelihood:-751492.18\n",
            "2020-12-02 08:51:28 INFO:GibbsSupervisedLDA:[ITER] 13,\tMAE:0.09,\tlog_likelihood:-750985.46\n",
            "2020-12-02 08:51:32 INFO:GibbsSupervisedLDA:[ITER] 14,\tMAE:0.09,\tlog_likelihood:-749516.11\n",
            "2020-12-02 08:51:37 INFO:GibbsSupervisedLDA:[ITER] 15,\tMAE:0.09,\tlog_likelihood:-748781.95\n",
            "2020-12-02 08:51:42 INFO:GibbsSupervisedLDA:[ITER] 16,\tMAE:0.09,\tlog_likelihood:-748208.86\n",
            "2020-12-02 08:51:47 INFO:GibbsSupervisedLDA:[ITER] 17,\tMAE:0.08,\tlog_likelihood:-747186.92\n",
            "2020-12-02 08:51:51 INFO:GibbsSupervisedLDA:[ITER] 18,\tMAE:0.09,\tlog_likelihood:-746634.25\n",
            "2020-12-02 08:51:56 INFO:GibbsSupervisedLDA:[ITER] 19,\tMAE:0.09,\tlog_likelihood:-745546.89\n",
            "2020-12-02 08:52:01 INFO:GibbsSupervisedLDA:[ITER] 20,\tMAE:0.09,\tlog_likelihood:-744768.82\n",
            "2020-12-02 08:52:06 INFO:GibbsSupervisedLDA:[ITER] 21,\tMAE:0.09,\tlog_likelihood:-744664.21\n",
            "2020-12-02 08:52:10 INFO:GibbsSupervisedLDA:[ITER] 22,\tMAE:0.08,\tlog_likelihood:-744224.22\n",
            "2020-12-02 08:52:15 INFO:GibbsSupervisedLDA:[ITER] 23,\tMAE:0.08,\tlog_likelihood:-743536.46\n",
            "2020-12-02 08:52:20 INFO:GibbsSupervisedLDA:[ITER] 24,\tMAE:0.08,\tlog_likelihood:-743032.18\n",
            "2020-12-02 08:52:24 INFO:GibbsSupervisedLDA:[ITER] 25,\tMAE:0.09,\tlog_likelihood:-742314.54\n",
            "2020-12-02 08:52:29 INFO:GibbsSupervisedLDA:[ITER] 26,\tMAE:0.09,\tlog_likelihood:-742439.52\n",
            "2020-12-02 08:52:34 INFO:GibbsSupervisedLDA:[ITER] 27,\tMAE:0.08,\tlog_likelihood:-742291.46\n",
            "2020-12-02 08:52:39 INFO:GibbsSupervisedLDA:[ITER] 28,\tMAE:0.08,\tlog_likelihood:-741981.16\n",
            "2020-12-02 08:52:44 INFO:GibbsSupervisedLDA:[ITER] 29,\tMAE:0.08,\tlog_likelihood:-741281.54\n",
            "2020-12-02 08:52:48 INFO:GibbsSupervisedLDA:[ITER] 30,\tMAE:0.08,\tlog_likelihood:-741008.93\n",
            "2020-12-02 08:52:53 INFO:GibbsSupervisedLDA:[ITER] 31,\tMAE:0.08,\tlog_likelihood:-740290.38\n",
            "2020-12-02 08:52:58 INFO:GibbsSupervisedLDA:[ITER] 32,\tMAE:0.08,\tlog_likelihood:-740521.22\n",
            "2020-12-02 08:53:03 INFO:GibbsSupervisedLDA:[ITER] 33,\tMAE:0.08,\tlog_likelihood:-740105.16\n",
            "2020-12-02 08:53:08 INFO:GibbsSupervisedLDA:[ITER] 34,\tMAE:0.08,\tlog_likelihood:-739782.71\n",
            "2020-12-02 08:53:12 INFO:GibbsSupervisedLDA:[ITER] 35,\tMAE:0.08,\tlog_likelihood:-738938.34\n",
            "2020-12-02 08:53:17 INFO:GibbsSupervisedLDA:[ITER] 36,\tMAE:0.08,\tlog_likelihood:-739070.42\n",
            "2020-12-02 08:53:22 INFO:GibbsSupervisedLDA:[ITER] 37,\tMAE:0.08,\tlog_likelihood:-739240.30\n",
            "2020-12-02 08:53:27 INFO:GibbsSupervisedLDA:[ITER] 38,\tMAE:0.09,\tlog_likelihood:-738999.52\n",
            "2020-12-02 08:53:31 INFO:GibbsSupervisedLDA:[ITER] 39,\tMAE:0.08,\tlog_likelihood:-738974.75\n",
            "2020-12-02 08:53:36 INFO:GibbsSupervisedLDA:[ITER] 40,\tMAE:0.08,\tlog_likelihood:-738126.28\n",
            "2020-12-02 08:53:41 INFO:GibbsSupervisedLDA:[ITER] 41,\tMAE:0.08,\tlog_likelihood:-737915.45\n",
            "2020-12-02 08:53:46 INFO:GibbsSupervisedLDA:[ITER] 42,\tMAE:0.08,\tlog_likelihood:-737514.68\n",
            "2020-12-02 08:53:50 INFO:GibbsSupervisedLDA:[ITER] 43,\tMAE:0.08,\tlog_likelihood:-737431.28\n",
            "2020-12-02 08:53:55 INFO:GibbsSupervisedLDA:[ITER] 44,\tMAE:0.08,\tlog_likelihood:-736997.02\n",
            "2020-12-02 08:54:00 INFO:GibbsSupervisedLDA:[ITER] 45,\tMAE:0.08,\tlog_likelihood:-736659.48\n",
            "2020-12-02 08:54:05 INFO:GibbsSupervisedLDA:[ITER] 46,\tMAE:0.08,\tlog_likelihood:-736685.83\n",
            "2020-12-02 08:54:10 INFO:GibbsSupervisedLDA:[ITER] 47,\tMAE:0.08,\tlog_likelihood:-736681.07\n",
            "2020-12-02 08:54:14 INFO:GibbsSupervisedLDA:[ITER] 48,\tMAE:0.08,\tlog_likelihood:-735943.68\n",
            "2020-12-02 08:54:19 INFO:GibbsSupervisedLDA:[ITER] 49,\tMAE:0.09,\tlog_likelihood:-736318.24\n",
            "2020-12-02 08:54:24 INFO:GibbsSupervisedLDA:[ITER] 50,\tMAE:0.08,\tlog_likelihood:-736054.04\n",
            "2020-12-02 08:54:29 INFO:GibbsSupervisedLDA:[ITER] 51,\tMAE:0.08,\tlog_likelihood:-735998.13\n",
            "2020-12-02 08:54:34 INFO:GibbsSupervisedLDA:[ITER] 52,\tMAE:0.08,\tlog_likelihood:-736118.12\n",
            "2020-12-02 08:54:39 INFO:GibbsSupervisedLDA:[ITER] 53,\tMAE:0.08,\tlog_likelihood:-735651.49\n",
            "2020-12-02 08:54:43 INFO:GibbsSupervisedLDA:[ITER] 54,\tMAE:0.08,\tlog_likelihood:-735974.62\n",
            "2020-12-02 08:54:48 INFO:GibbsSupervisedLDA:[ITER] 55,\tMAE:0.08,\tlog_likelihood:-735923.45\n",
            "2020-12-02 08:54:53 INFO:GibbsSupervisedLDA:[ITER] 56,\tMAE:0.08,\tlog_likelihood:-735415.73\n",
            "2020-12-02 08:54:58 INFO:GibbsSupervisedLDA:[ITER] 57,\tMAE:0.08,\tlog_likelihood:-735217.80\n",
            "2020-12-02 08:55:03 INFO:GibbsSupervisedLDA:[ITER] 58,\tMAE:0.08,\tlog_likelihood:-735020.37\n",
            "2020-12-02 08:55:07 INFO:GibbsSupervisedLDA:[ITER] 59,\tMAE:0.08,\tlog_likelihood:-734782.97\n",
            "2020-12-02 08:55:12 INFO:GibbsSupervisedLDA:[ITER] 60,\tMAE:0.08,\tlog_likelihood:-735348.02\n",
            "2020-12-02 08:55:17 INFO:GibbsSupervisedLDA:[ITER] 61,\tMAE:0.08,\tlog_likelihood:-734923.58\n",
            "2020-12-02 08:55:22 INFO:GibbsSupervisedLDA:[ITER] 62,\tMAE:0.08,\tlog_likelihood:-734434.06\n",
            "2020-12-02 08:55:27 INFO:GibbsSupervisedLDA:[ITER] 63,\tMAE:0.08,\tlog_likelihood:-734390.01\n",
            "2020-12-02 08:55:31 INFO:GibbsSupervisedLDA:[ITER] 64,\tMAE:0.08,\tlog_likelihood:-733942.11\n",
            "2020-12-02 08:55:36 INFO:GibbsSupervisedLDA:[ITER] 65,\tMAE:0.08,\tlog_likelihood:-734177.31\n",
            "2020-12-02 08:55:41 INFO:GibbsSupervisedLDA:[ITER] 66,\tMAE:0.08,\tlog_likelihood:-733999.27\n",
            "2020-12-02 08:55:46 INFO:GibbsSupervisedLDA:[ITER] 67,\tMAE:0.08,\tlog_likelihood:-734118.22\n",
            "2020-12-02 08:55:50 INFO:GibbsSupervisedLDA:[ITER] 68,\tMAE:0.08,\tlog_likelihood:-733837.00\n",
            "2020-12-02 08:55:55 INFO:GibbsSupervisedLDA:[ITER] 69,\tMAE:0.08,\tlog_likelihood:-734027.64\n",
            "2020-12-02 08:56:00 INFO:GibbsSupervisedLDA:[ITER] 70,\tMAE:0.08,\tlog_likelihood:-734038.95\n",
            "2020-12-02 08:56:05 INFO:GibbsSupervisedLDA:[ITER] 71,\tMAE:0.08,\tlog_likelihood:-733420.72\n",
            "2020-12-02 08:56:09 INFO:GibbsSupervisedLDA:[ITER] 72,\tMAE:0.08,\tlog_likelihood:-733270.05\n",
            "2020-12-02 08:56:14 INFO:GibbsSupervisedLDA:[ITER] 73,\tMAE:0.08,\tlog_likelihood:-733352.35\n",
            "2020-12-02 08:56:19 INFO:GibbsSupervisedLDA:[ITER] 74,\tMAE:0.08,\tlog_likelihood:-733415.36\n",
            "2020-12-02 08:56:24 INFO:GibbsSupervisedLDA:[ITER] 75,\tMAE:0.08,\tlog_likelihood:-732987.55\n",
            "2020-12-02 08:56:29 INFO:GibbsSupervisedLDA:[ITER] 76,\tMAE:0.08,\tlog_likelihood:-733032.93\n",
            "2020-12-02 08:56:34 INFO:GibbsSupervisedLDA:[ITER] 77,\tMAE:0.08,\tlog_likelihood:-733104.63\n",
            "2020-12-02 08:56:38 INFO:GibbsSupervisedLDA:[ITER] 78,\tMAE:0.08,\tlog_likelihood:-732849.59\n",
            "2020-12-02 08:56:43 INFO:GibbsSupervisedLDA:[ITER] 79,\tMAE:0.08,\tlog_likelihood:-733093.78\n",
            "2020-12-02 08:56:48 INFO:GibbsSupervisedLDA:[ITER] 80,\tMAE:0.08,\tlog_likelihood:-732439.93\n",
            "2020-12-02 08:56:53 INFO:GibbsSupervisedLDA:[ITER] 81,\tMAE:0.08,\tlog_likelihood:-732709.08\n",
            "2020-12-02 08:56:57 INFO:GibbsSupervisedLDA:[ITER] 82,\tMAE:0.08,\tlog_likelihood:-732527.17\n",
            "2020-12-02 08:57:02 INFO:GibbsSupervisedLDA:[ITER] 83,\tMAE:0.09,\tlog_likelihood:-732605.18\n",
            "2020-12-02 08:57:07 INFO:GibbsSupervisedLDA:[ITER] 84,\tMAE:0.08,\tlog_likelihood:-732061.98\n",
            "2020-12-02 08:57:12 INFO:GibbsSupervisedLDA:[ITER] 85,\tMAE:0.08,\tlog_likelihood:-732121.15\n",
            "2020-12-02 08:57:17 INFO:GibbsSupervisedLDA:[ITER] 86,\tMAE:0.08,\tlog_likelihood:-731590.11\n",
            "2020-12-02 08:57:21 INFO:GibbsSupervisedLDA:[ITER] 87,\tMAE:0.08,\tlog_likelihood:-732080.49\n",
            "2020-12-02 08:57:26 INFO:GibbsSupervisedLDA:[ITER] 88,\tMAE:0.08,\tlog_likelihood:-731904.77\n",
            "2020-12-02 08:57:31 INFO:GibbsSupervisedLDA:[ITER] 89,\tMAE:0.08,\tlog_likelihood:-731521.70\n",
            "2020-12-02 08:57:36 INFO:GibbsSupervisedLDA:[ITER] 90,\tMAE:0.08,\tlog_likelihood:-732108.26\n",
            "2020-12-02 08:57:41 INFO:GibbsSupervisedLDA:[ITER] 91,\tMAE:0.08,\tlog_likelihood:-731733.71\n",
            "2020-12-02 08:57:45 INFO:GibbsSupervisedLDA:[ITER] 92,\tMAE:0.08,\tlog_likelihood:-731385.70\n",
            "2020-12-02 08:57:50 INFO:GibbsSupervisedLDA:[ITER] 93,\tMAE:0.08,\tlog_likelihood:-731587.68\n",
            "2020-12-02 08:57:55 INFO:GibbsSupervisedLDA:[ITER] 94,\tMAE:0.08,\tlog_likelihood:-731086.52\n",
            "2020-12-02 08:58:00 INFO:GibbsSupervisedLDA:[ITER] 95,\tMAE:0.08,\tlog_likelihood:-730905.91\n",
            "2020-12-02 08:58:04 INFO:GibbsSupervisedLDA:[ITER] 96,\tMAE:0.08,\tlog_likelihood:-730640.27\n",
            "2020-12-02 08:58:09 INFO:GibbsSupervisedLDA:[ITER] 97,\tMAE:0.08,\tlog_likelihood:-731090.46\n",
            "2020-12-02 08:58:14 INFO:GibbsSupervisedLDA:[ITER] 98,\tMAE:0.08,\tlog_likelihood:-730645.27\n",
            "2020-12-02 08:58:19 INFO:GibbsSupervisedLDA:[ITER] 99,\tMAE:0.08,\tlog_likelihood:-730381.74\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUhQWSAdpfd6",
        "outputId": "ae8c0069-2575-4757-b7e3-321c1d62f6bc"
      },
      "source": [
        "for ti in model.eta.argsort():\n",
        "    top_words = get_top_words(model.TW, voca, ti, n_words=15)\n",
        "    print('Eta', model.eta[ti] ,'Topic', ti ,':\\t', ','.join(top_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eta -9.648747873657326 Topic 6 :\t like,could,better,much,well,want,know,bad,money,terrible,may,maybe,one,think,nice\n",
            "Eta -8.84515312856964 Topic 10 :\t would,back,order,said,bad,going,pretty,go,three,came,first,restaurant,dinner,say,also\n",
            "Eta -6.23943826918899 Topic 19 :\t little,see,parking,open,inside,like,nothing,people,getting,though,wait,dining,finally,list,giving\n",
            "Eta -3.6967637326122604 Topic 5 :\t time,one,went,first,like,really,told,check,actually,try,nothing,working,see,around,finally\n",
            "Eta -3.4095782618190533 Topic 13 :\t us,would,never,could,another,said,get,came,got,back,made,took,manager,table,later\n",
            "Eta -2.9232349569351035 Topic 1 :\t one,however,even,every,main,airport,nothing,counter,white,store,trip,far,line,major,mess\n",
            "Eta -1.5821067761173904 Topic 7 :\t chicken,get,rice,hot,better,got,meat,cook,either,water,sandwich,way,indian,beef,enough\n",
            "Eta 0.004157330046476587 Topic 8 :\t cheese,ordered,sauce,also,soup,like,french,chicken,decent,much,well,quality,maybe,bland,taste\n",
            "Eta 0.563983060988243 Topic 12 :\t call,told,people,one,make,customer,know,right,phone,extra,ever,business,way,received,company\n",
            "Eta 2.400015992484731 Topic 16 :\t bar,nice,area,sunday,old,pretty,beer,night,cool,drink,fun,kids,stand,atmosphere,show\n",
            "Eta 3.9173522897481954 Topic 14 :\t like,one,two,would,mexican,go,yelp,though,look,chips,take,art,burrito,fresh,days\n",
            "Eta 4.269881577031333 Topic 9 :\t time,back,going,first,thai,visit,staff,way,friend,go,spicy,fine,already,last,fan\n",
            "Eta 4.428994820062925 Topic 4 :\t room,hotel,location,stay,pool,staff,parking,need,free,front,lot,stayed,time,day,view\n",
            "Eta 5.16093000626631 Topic 18 :\t de,plus,la,kids,fitness,fun,plan,gym,un,level,together,class,training,needs,les\n",
            "Eta 5.488577869638565 Topic 17 :\t car,work,new,shop,done,rex,got,price,recommend,never,well,oil,took,found,care\n",
            "Eta 5.821310548824171 Topic 15 :\t get,even,would,hair,done,one,job,work,best,dog,know,home,dogs,need,appointment\n",
            "Eta 5.852601897869069 Topic 3 :\t us,massage,see,card,little,two,time,definitely,gave,city,show,three,someone,found,getting\n",
            "Eta 6.037536789843898 Topic 0 :\t delicious,like,really,menu,best,ordered,try,restaurant,love,also,one,salad,nice,amazing,little\n",
            "Eta 6.4211999783238385 Topic 2 :\t really,get,go,time,like,back,come,nice,one,would,friendly,always,wait,staff,experience\n",
            "Eta 7.010008438727509 Topic 11 :\t new,could,store,get,help,also,day,much,business,less,would,came,problem,days,felt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvTpvBsRtTdQ"
      },
      "source": [
        "Question 1:\n",
        "1.Try this amazing restaurent which serves which serves delicious salads\n",
        "2.Every  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgQCDmh-rUBx"
      },
      "source": [
        "import logging\n",
        "from ptm.nltk_corpus import get_reuters_token_list_by_sentence\n",
        "from ptm import HMM_LDA\n",
        "from ptm.utils import get_top_words\n",
        "\n",
        "logger = logging.getLogger('HMM_LDA')\n",
        "logger.propagate=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHMbnlymsQpH"
      },
      "source": [
        "corpus=[corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7XKwU_3rfKu"
      },
      "source": [
        "n_docs = len(corpus)\n",
        "n_voca = len(voca)\n",
        "n_topic = 50\n",
        "n_class = 20\n",
        "max_iter = 100\n",
        "alpha = 0.1\n",
        "beta = 0.01\n",
        "gamma = 0.1\n",
        "eta = 0.1\n",
        "model = HMM_LDA(n_docs, n_voca, n_topic, n_class, alpha=alpha, beta=beta, gamma=gamma, eta=eta, verbose=False)\n",
        "model.fit(corpus, max_iter=max_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTQdFKlOwTK0",
        "outputId": "803c941f-2d08-476d-a0c7-9321e62f5fb8"
      },
      "source": [
        "for ti in range(n_topic):\n",
        "    top_words = get_top_words(model.TW, voca, ti, n_words=10)\n",
        "    print('Topic', ti ,': ', ','.join(top_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0 :  gently,small,times,big,tell,water,give,everything,tartar,alcohol\n",
            "Topic 1 :  one,crazy,plate,hair,least,plated,tonight,ice,rip,cityscape\n",
            "Topic 2 :  matter,give,confused,kids,holiday,around,cam,help,already,eating\n",
            "Topic 3 :  paper,weird,complexity,courteous,hot,broken,convention,meaty,medical,garden\n",
            "Topic 4 :  one,paint,within,deal,car,butter,dinner,side,last,combination\n",
            "Topic 5 :  fair,know,laugh,sure,since,chip,environment,prime,bit,times\n",
            "Topic 6 :  concourse,want,visit,brunch,favorite,chef,loud,number,forgotten,room\n",
            "Topic 7 :  help,amount,hot,meat,included,stuff,mad,incredibly,end,saturday\n",
            "Topic 8 :  ran,maintenance,point,venetian,less,fantastic,trying,gave,expect,regardless\n",
            "Topic 9 :  one,eating,sit,times,ended,outside,shelf,truly,general,everything\n",
            "Topic 10 :  morning,cheese,delivery,due,male,tables,breakfast,lucky,every,meatless\n",
            "Topic 11 :  one,help,scratch,dollar,plan,mine,fun,water,selection,busy\n",
            "Topic 12 :  though,super,rotation,part,number,help,create,done,mention,marshall\n",
            "Topic 13 :  friday,wonderful,ask,vic,total,easily,bean,deep,steak,valley\n",
            "Topic 14 :  dollar,contact,downside,mention,directly,took,read,steak,professional,solid\n",
            "Topic 15 :  one,still,rice,transaction,hot,without,ok,duck,customer,dinner\n",
            "Topic 16 :  one,yummy,pork,disagree,put,cut,massage,rental,hanging,inviting\n",
            "Topic 17 :  bottle,meat,wellness,almost,warranty,something,pizza,heading,beauty,meal\n",
            "Topic 18 :  one,find,competition,manner,tasty,coming,looking,delivery,visit,pot\n",
            "Topic 19 :  one,sexy,wedding,pizza,vinaigrette,add,fake,french,heat,ca\n",
            "Topic 20 :  walking,let,authentic,weak,recently,thought,attentive,pear,milk,longer\n",
            "Topic 21 :  cheap,total,large,raspberry,brown,awesome,wipe,every,next,area\n",
            "Topic 22 :  middle,happy,spot,treat,sandwich,medium,view,ask,waste,blanket\n",
            "Topic 23 :  brilliant,flavorful,life,sitting,admirable,equipment,ask,check,guess,rice\n",
            "Topic 24 :  one,work,kind,feature,near,fan,highly,actually,beef,soup\n",
            "Topic 25 :  soaking,couple,share,price,hostess,road,check,salad,point,founder\n",
            "Topic 26 :  one,keep,completely,steak,take,exactly,kitchen,aspect,sent,help\n",
            "Topic 27 :  mild,sauce,juicy,elvis,probably,bit,dining,fast,cheese,soft\n",
            "Topic 28 :  plug,took,side,dining,usually,tag,interesting,often,since,salad\n",
            "Topic 29 :  one,night,size,working,start,comes,scratching,beer,somewhat,specialist\n",
            "Topic 30 :  bread,timely,twice,look,three,security,fresh,old,work,mornings\n",
            "Topic 31 :  one,give,perfect,style,value,fault,reasonably,average,buy,home\n",
            "Topic 32 :  one,decided,knowledgeable,ice,someone,person,look,relaxed,old,fun\n",
            "Topic 33 :  one,sent,charge,walnut,job,thought,flavor,usual,away,check\n",
            "Topic 34 :  bad,thought,butter,truly,still,yard,label,brisket,many,seriously\n",
            "Topic 35 :  one,may,wide,parlor,request,ur,room,clean,sides,molly\n",
            "Topic 36 :  one,pure,seated,kee,enjoy,fantastic,coupon,high,large,painless\n",
            "Topic 37 :  least,blow,total,replacement,ceiling,tranquil,needs,enjoy,disappointed,expensive\n",
            "Topic 38 :  container,choice,job,sandwich,thought,medium,call,ask,free,ass\n",
            "Topic 39 :  must,nearby,part,surprise,chain,neither,server,location,previously,starter\n",
            "Topic 40 :  portion,sessions,lot,clean,venue,setting,dinner,chef,tiny,lunch\n",
            "Topic 41 :  morning,sal,wasnt,honest,higher,hard,urban,half,mains,highly\n",
            "Topic 42 :  voucher,black,professional,fantastic,unique,environment,stool,timely,throw,rethink\n",
            "Topic 43 :  last,immediately,plenty,deal,many,duck,grow,dinner,awesome,bad\n",
            "Topic 44 :  one,menu,delivery,soy,drink,salad,another,times,see,environment\n",
            "Topic 45 :  ceremony,tasty,bread,selection,radio,hubby,recognition,anywhere,error,sandwich\n",
            "Topic 46 :  red,gravy,done,gone,arrive,fruit,warranty,real,fin,less\n",
            "Topic 47 :  understand,work,bistro,remember,fore,take,see,eating,fresh,server\n",
            "Topic 48 :  one,work,substantially,tall,inside,overall,honest,couple,look,hawaiian\n",
            "Topic 49 :  one,blonde,manager,spicy,dance,reasonably,diego,potatoes,let,else\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Yelp Review Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-veaZkZpG-z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.\n",
        "\n",
        "The data can be download from Dropbox: https://www.dropbox.com/s/59hsrk56sfwh9u2/Assignment%20four%20data%20Yelp%20%28question%201%20and%202%29.zip?dl=0 \n",
        "\n",
        "The data was saved in json format, here is an example of the data (for this task, you only need to use the star rating and the review text fields):\n",
        "\n",
        "{\n",
        "    // string, 22 character unique review id\n",
        "    \"review_id\": \"zdSx_SD6obEhz9VrW9uAWA\",\n",
        "\n",
        "    // string, 22 character unique user id, maps to the user in user.json\n",
        "    \"user_id\": \"Ha3iJu77CxlrFm-vQRs_8g\",\n",
        "\n",
        "    // string, 22 character business id, maps to business in business.json\n",
        "    \"business_id\": \"tnhfDv5Il8EaGSXZGiuQGg\",\n",
        "\n",
        "    // integer, star rating\n",
        "    \"stars\": 4,\n",
        "\n",
        "    // string, date formatted YYYY-MM-DD\n",
        "    \"date\": \"2016-03-09\",\n",
        "\n",
        "    // string, the review itself\n",
        "    \"text\": \"Great place to hang out after work: the prices are decent, and the ambience is fun. It's a bit loud, but very lively. The staff is friendly, and the food is good. They have a good selection of drinks.\",\n",
        "\n",
        "    // integer, number of useful votes received\n",
        "    \"useful\": 0,\n",
        "\n",
        "    // integer, number of funny votes received\n",
        "    \"funny\": 0,\n",
        "\n",
        "    // integer, number of cool votes received\n",
        "    \"cool\": 0\n",
        "}\n",
        "\n",
        "The sentiment of can be accessed based on the star rating, if no star information avaliable for a record, just remove that record. Detail star and sentiment level can be matched blew:\n",
        "\n",
        "Very positive = 5 stars\n",
        "\n",
        "Positive = 4 stars\n",
        "\n",
        "Neutral = 3 stars\n",
        "\n",
        "Negative = 2 stars\n",
        "\n",
        "Very negative = 1 star\n",
        "\n",
        "Here is code for yelp data preprocessing: https://github.com/Yelp/dataset-examples. \n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features (tf-idf, sentiment lexicon, word2vec, etc). Considering achieve the best performance as you can. \n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. \n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA"
      },
      "source": [
        "# Write your code here\n",
        "df.loc[df['ratings']==5.0, 'sentiment'] = 'very_positve'\n",
        "df.loc[df['ratings']==4.0, 'sentiment'] = 'Positve'\n",
        "df.loc[df['ratings']==3.0, 'sentiment'] = 'Neutral'\n",
        "df.loc[df['ratings']==2.0, 'sentiment'] = 'Negative'\n",
        "df.loc[df['ratings']==1.0, 'sentiment'] = 'very_Negative'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kVsa5Fe1vDM"
      },
      "source": [
        "df=df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFg3hg4tznJa",
        "outputId": "58e66455-8a24-4d37-855d-02db0b1d54f2"
      },
      "source": [
        "X = df.iloc[:, 0].values\n",
        "y = df.iloc[:, 2].values\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "td = TfidfVectorizer(max_features = 4500)\n",
        "X = td.fit_transform(X).toarray()\n",
        "\n",
        "# Splitting into training & test subsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,\n",
        "                                                    random_state = 0)\n",
        "\n",
        "# Training the classifier & predicting on test data\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Classification metrics\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "classification_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print('\\n Accuracy using Multinomial navie bayes: ', accuracy_score(y_test, y_pred))\n",
        "print('\\nClassification Report')\n",
        "print('======================================================')\n",
        "print('\\n', classification_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Accuracy using Multinomial navie bayes:  0.4222222222222222\n",
            "\n",
            "Classification Report\n",
            "======================================================\n",
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     Negative       0.00      0.00      0.00        47\n",
            "      Neutral       0.00      0.00      0.00        74\n",
            "      Positve       0.33      0.01      0.01       157\n",
            "very_Negative       0.00      0.00      0.00        87\n",
            " very_positve       0.42      1.00      0.59       265\n",
            "\n",
            "     accuracy                           0.42       630\n",
            "    macro avg       0.15      0.20      0.12       630\n",
            " weighted avg       0.26      0.42      0.25       630\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiWSuMr42NzS",
        "outputId": "4825af43-22b8-41ab-b654-063f96647df4"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "svm_classifier=LinearSVC()\n",
        "svm_classifier.fit(X_train,y_train)\n",
        "y_pred=svm_classifier.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "classification_report=classification_report(y_test,y_pred)\n",
        "print('\\n Accuracy using support vector machine: ', accuracy_score(y_test, y_pred))\n",
        "print('\\nClassification Report')\n",
        "print('======================================================')\n",
        "print('\\n', classification_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Accuracy using support vector machine:  0.5746031746031746\n",
            "\n",
            "Classification Report\n",
            "======================================================\n",
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     Negative       0.39      0.15      0.22        47\n",
            "      Neutral       0.38      0.16      0.23        74\n",
            "      Positve       0.43      0.40      0.41       157\n",
            "very_Negative       0.72      0.71      0.72        87\n",
            " very_positve       0.63      0.82      0.71       265\n",
            "\n",
            "     accuracy                           0.57       630\n",
            "    macro avg       0.51      0.45      0.46       630\n",
            " weighted avg       0.54      0.57      0.54       630\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from Dropbox: https://www.dropbox.com/s/52j9hpxppfo921o/assignment4-question3-data.zip?dl=0. Here is an axample for the implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMKJjIXS5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811ca70f-69bc-4899-97ae-0fb393e0dd58"
      },
      "source": [
        "# Write your code here\n",
        "train=pd.read_csv('/content/train.csv')\n",
        "train.columns\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
              "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
              "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
              "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
              "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
              "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
              "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
              "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
              "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
              "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
              "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
              "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
              "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
              "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
              "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
              "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
              "       'SaleCondition', 'SalePrice'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvM0JwRL9J7G"
      },
      "source": [
        "train_missing = train.isna()\n",
        "train_num_missing = train_missing.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDwH8PNb9WRO",
        "outputId": "a87160a6-d242-4720-cb5e-cf6591ac3c63"
      },
      "source": [
        "miss=train_num_missing/len(train)\n",
        "miss=miss.sort_values()\n",
        "miss.tail(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GarageFinish    0.055479\n",
              "GarageYrBlt     0.055479\n",
              "GarageType      0.055479\n",
              "GarageCond      0.055479\n",
              "LotFrontage     0.177397\n",
              "FireplaceQu     0.472603\n",
              "Fence           0.807534\n",
              "Alley           0.937671\n",
              "MiscFeature     0.963014\n",
              "PoolQC          0.995205\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYz09qdk_QTV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "44a9c744-fde6-40a7-f453-544df88bda05"
      },
      "source": [
        "train.drop(['FireplaceQu','Fence','Alley','MiscFeature','PoolQC','LotFrontage'],axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>1456</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>7917</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Gilbert</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1999</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>953</td>\n",
              "      <td>953</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>953</td>\n",
              "      <td>694</td>\n",
              "      <td>0</td>\n",
              "      <td>1647</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>1457</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>13175</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NWAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1978</td>\n",
              "      <td>1988</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>Stone</td>\n",
              "      <td>119.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>790</td>\n",
              "      <td>Rec</td>\n",
              "      <td>163</td>\n",
              "      <td>589</td>\n",
              "      <td>1542</td>\n",
              "      <td>GasA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>2073</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2073</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>7</td>\n",
              "      <td>Min1</td>\n",
              "      <td>2</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1978.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>2</td>\n",
              "      <td>500</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>1458</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>9042</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1941</td>\n",
              "      <td>2006</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>CemntBd</td>\n",
              "      <td>CmentBd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Stone</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>275</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>877</td>\n",
              "      <td>1152</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1188</td>\n",
              "      <td>1152</td>\n",
              "      <td>0</td>\n",
              "      <td>2340</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>2</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1941.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>1</td>\n",
              "      <td>252</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2500</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>266500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>1459</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>9717</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1950</td>\n",
              "      <td>1996</td>\n",
              "      <td>Hip</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>49</td>\n",
              "      <td>Rec</td>\n",
              "      <td>1029</td>\n",
              "      <td>0</td>\n",
              "      <td>1078</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>FuseA</td>\n",
              "      <td>1078</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1078</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>5</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1950.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1</td>\n",
              "      <td>240</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>366</td>\n",
              "      <td>0</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>142125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>1460</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>9937</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Edwards</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1965</td>\n",
              "      <td>1965</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>BLQ</td>\n",
              "      <td>830</td>\n",
              "      <td>LwQ</td>\n",
              "      <td>290</td>\n",
              "      <td>136</td>\n",
              "      <td>1256</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1256</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1256</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1965.0</td>\n",
              "      <td>Fin</td>\n",
              "      <td>1</td>\n",
              "      <td>276</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>736</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>147500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows  75 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  MSSubClass MSZoning  ...  SaleType SaleCondition SalePrice\n",
              "0        1          60       RL  ...        WD        Normal    208500\n",
              "1        2          20       RL  ...        WD        Normal    181500\n",
              "2        3          60       RL  ...        WD        Normal    223500\n",
              "3        4          70       RL  ...        WD       Abnorml    140000\n",
              "4        5          60       RL  ...        WD        Normal    250000\n",
              "...    ...         ...      ...  ...       ...           ...       ...\n",
              "1455  1456          60       RL  ...        WD        Normal    175000\n",
              "1456  1457          20       RL  ...        WD        Normal    210000\n",
              "1457  1458          70       RL  ...        WD        Normal    266500\n",
              "1458  1459          20       RL  ...        WD        Normal    142125\n",
              "1459  1460          20       RL  ...        WD        Normal    147500\n",
              "\n",
              "[1460 rows x 75 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWiHRk_e6V29"
      },
      "source": [
        "X=train.drop(['SalePrice'],axis=1)\n",
        "Y=train['SalePrice']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "keXCQsjj6unr",
        "outputId": "9226736b-243a-41e8-8b48-5156e4f2c986"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-dfa52fd2523b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 492\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'RL'"
          ]
        }
      ]
    }
  ]
}